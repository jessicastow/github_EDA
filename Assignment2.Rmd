---
title: "STA5092Z: Exploratory Data Analysis on Earthquake Data"
author: "Jessica Stow (STWJES003)"
date: "March 2024"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, include = TRUE)
```

\newpage

**Plagiarism declaration**

I know that plagiarism is wrong. 
Plagiarism is to use another's work and pretend that it is one's own.
I have used the required convention for citation and referencing. 
Each contribution to and quotation in this assignment from the work(s) of other people has been attributed, and has been cited and referenced.
This assignment is my own work.
I have not allowed, and will not allow, anyone to copy my work with the intention of passing it off as his or her own work.
I acknowledge that copying someone else's assignment or essay, or part of it, is wrong, and declare that this is my own work.

\newpage

# Introduction

This report uses exploratory data analysis to wrangle, explore and present data findings using data from global earthquake occurrences (or other extreme events) over the period of 4 January 1965 until 17 March 2023. Two datasets, sourced from Kaggle **(link)** and the United States Geological Survey (USGS) **(link)**, were wrangled to create a single dataframe. Only common variables between the two datasets were included in the final dataframe. 

The date-time variables were standardised (making sure there was only one column for the date-time). The challenges posed by overlapping time frames was addressed by removing observations from the Kaggle dataset. For the analysis of earthquake magnitude ranges (based on the Richter scale), outliers and inconsistencies were identified, however no data was removed as all measurements fell within the expected range. The presence of missing data (in the form of NA values) across all common variables was assessed, and the feasibility of retaining information for variables with significant missing data, or discrepancies in values, was determined. It was decided that the following variables would not be used in the analyses due to their incompleteness: **XYZ.**

The dataset was filtered to include only Earthquake events, and a categorical variable "Scale" was created to classify earthquakes by magnitude as per the descriptions laid out in **link**.

The report then explores the dataset's features, examines the distribution of these features, identifies significant earthquakes by magnitude, and investigates the relationship between depth and magnitude. The initial exploration section aimed to uncover patterns and insights, and adjusted for the logarithmic nature of the Richter scale to provide a more accurate representation of magnitude. Furthermore, the temporal and spacial nature of nuclear explosion events was briefly investigated and a map to visualise these investigations was produced.

In the temporal investigation section, and analysis of the frequency and severity of earthquakes over the decades was done and the observed data was compared with estimated frequencies  (link). A search for patterns that could indicate underlying seismic behaviour or artifacts of the data collection process was also undertaken.

In the spatial exploration section, a comprehensive map of the global distribution of earthquakes, incorporating temporal data to enhance the analysis, was provided. This included focused examinations of specific regions: Türkiye, in the context of the 2023 earthquake; Southern Africa, to understand its seismic history since 1965; and the Mentawai region, a region of personal interest, to provide targeted insights into these seismic activities.

The report concludes with a summary of the key findings, offering insights derived from the compiled and analysed dataset. This dataset exploration not only contributes to the understanding of the complexities of earthquake data but also highlights the significance of seismic risks and patterns across different regions of the world.

# Dataset overview


# Data Wrangling

The following packages were installed: tidyverse, lubridate, ggplot2, sf, dplyr
```{r include = FALSE}
library(tidyverse)
library(lubridate)
library(ggplot2)
library(sf)
library(dplyr)
library(readr)

library(raster)
library(leaflet)
library(stringr)
library(tmap)
library(spData)

library(webshot)
```

The data from the "Earthquakes 1965 - 2016.csv" file (sourced from Kaggle) and the "query.csv" file (sourced from USGS) were read into R as two separate dataframes. The dataframes were named `earthquakes` and `query`, respectively.
```{r include = FALSE}
earthquakes <-read.csv("Earthquakes 1965 - 2016.csv")
query <- read.csv("query.csv")
```

The column names and their respective data types for the `earthquakes` dataset were as follows:
```{r}
str(earthquakes)
```

The column names and their respective data types for the `query` dataframe were as follows:
```{r}
str(query)
```

In the `query` dataframe, the `time` column contains milliseconds and is in a different format from that in the `earthquakes` table. The milliseconds were removed from the column and column was formatted as a datetime datatype. 
```{r}
query <- query %>%
  mutate(time = ymd_hms(time)) # remove the milliseconds from the column (this also formats the column to the correct data type)
```

For the `earthquake` dataframe, the `Date` and `Time` columns were combined into one column `DateTime` and then converted to a datetime datatype using lubridates' `mdy_hms()` function. This step was done to ensure there was only one date-time variable. Three rows, namely rows 20651, 7513 and 3379 did not adhere to the format needed for conversion to a datetime datatype and these three data points were removed. 
```{r}
earthquakes <- earthquakes[-c(20651, 7513, 3379), ] # Exclude specified rows that are issues

earthquakes$DateTime <- paste(earthquakes$Date, earthquakes$Time) # Combine the `Date` and `Time` columns 

earthquakes$DateTime <- mdy_hms(as.character(earthquakes$DateTime, 
                                             format = "%m/%d/%Y %H:%M:%S")) # convert to datetime

class(earthquakes$DateTime) # Check the class has been correclty converted to "POSIXct" "POSIXt"
```

The `Date` and `Time` columns in the `earthquakes` dataframe were then dropped.
```{r}
earthquakes <- subset(earthquakes, select = -c(Date, Time))
```

Variables that were not shared between dataframes were dropped so that only similar information contained in both datasets was used for the final unified dataframe.

For the `query` dataframe this involved dropping the following columns: `place`, `net`, `status`, `updated`, `locationSource` and `magSource` columns.
```{r}
query <- subset(query, 
                select = -c(place, net, status, updated, locationSource, magSource))
```

For the `earthquake` dataframe this involved dropping the following columns: `Source`, `Location.Source`, `Magnitude.Source`, and `Status`.
```{r}
earthquakes <- subset(earthquakes, 
                      select = -c(Source, Location.Source, Magnitude.Source, Status))
```

The column names were renamed to match each other for when binding the dataframes later.
```{r}
# Rename 'query' column names
query <- rename(query,
                Type = type, 
                DepthSeismicStation = nst,
                DateTime = time,
                Latitude = latitude,
                Longitude = longitude,
                Depth = depth,
                Magnitude = mag, 
                MagType = magType,
                AzimuthalGap = gap, 
                HorizontalDistance = dmin,
                RootMeanSquare = rms,  
                ID = id,
                HorizontalError = horizontalError, 
                DepthError = depthError,
                MagError = magError,
                MagnitudeSeismicStation = magNst)

str(query) # Check columns were renamed
```


```{r}
# Rename 'query' column names
earthquakes <- rename(earthquakes, 
                      DepthError = Depth.Error,
                      DepthSeismicStation = Depth.Seismic.Stations,
                      MagType = Magnitude.Type, 
                      MagError = Magnitude.Error, 
                      MagnitudeSeismicStation = Magnitude.Seismic.Stations,
                      AzimuthalGap = Azimuthal.Gap, 
                      HorizontalDistance = Horizontal.Distance, 
                      HorizontalError = Horizontal.Error,
                      RootMeanSquare = Root.Mean.Square)

str(earthquakes) # Check columns were renamed
```

The time frames overlap, so the `earthquakes` dataframe to only include dates up to, but not including, 1 December 2016. 
```{r}
earthquakes <- earthquakes %>% 
  filter(DateTime < as.Date("2016-12-01"))

max(earthquakes$DateTime, na.rm = TRUE) # earthquakes latest date is now 30 Nov 2016

min(query$DateTime, na.rm = TRUE) # query earliest date is 1 Dec 2016

# There is now no overlap in dates so the dataframes can be combined.
```

A column `Dataframe` was added to note from which dataframe the rows were obtained.
```{r}
query <- query %>%
  mutate(Dataframe = "query")

earthquakes <- earthquakes %>%
  mutate(Dataframe = "earthquakes")
```

The dataframes were combined into one unified dataframe `df`. The final dataframe was as follows:
```{r}
df <- rbind(earthquakes, query)
head(df, n=4)
```

There are five different event types included in this dataset, namely: earthquakes, nuclear explosions, rock bursts, volcanic eruptions and explosions.
```{r}
unique(df$Type)

# "Earthquake"        "Nuclear Explosion" "Explosion"         "Rock Burst"        "earthquake"       
# "volcanic eruption" "nuclear explosion"
```

The observations were filtered to only include “Earthquake” type events.
```{r}
df_earthquakes <- subset(df, Type == c("earthquake", "Earthquake")) # keep rows where the event type "Type" is "earthquake"
```

A categorical variable “Scale”, which classifies the earthquakes according to their magnitude, was added. These scale categories were classified and assigned according to the “Description” column in the table on this page https://en.wikipedia.org/wiki/Richter_scale#cite_note-13 
```{r}
df_earthquakes <- df_earthquakes %>%
  mutate(Scale = case_when(
    Magnitude >= 1.0 & Magnitude < 2.0 ~ "Micro",
    Magnitude >= 2.0 & Magnitude < 3.0 ~ "Minor",
    Magnitude >= 3.0 & Magnitude < 4.0 ~ "Slight",
    Magnitude >= 4.0 & Magnitude < 5.0 ~ "Light",
    Magnitude >= 5.0 & Magnitude < 6.0 ~ "Moderate",
    Magnitude >= 6.0 & Magnitude < 7.0 ~ "Strong",
    Magnitude >= 7.0 & Magnitude < 8.0 ~ "Major",
    Magnitude >= 8.0 & Magnitude < 9.0 ~ "Great",
    Magnitude >= 9.0 & Magnitude < 10.0 ~ "Extreme"))
```

Explore the range of magnitudes (Richter scale) in both datasets. Is there a reason to exclude any measurements in either? Implement and discuss briefly.

I don't think there is any reason to exclude any measurements in either data set for the magnitude column since they all fall within the expected range of earthquakes that are of interest - between 5 and 9.1. Since most of the magnitude data lies on the lower end (below 5.6), the data are not normally distributed. However, it is important to remember that these datasets did not record minor earthquakes. 

No data recorded for micro, minor, slight and light earthquake types - probably because they are only slightly felt. read more  https://en.wikipedia.org/wiki/Richter_scale#cite_note-13

```{r}
summary(df$Magnitude)

min(df_earthquakes$Magnitude) # minimum 5
median(df_earthquakes$Magnitude) # median 5.6
max(df_earthquakes$Magnitude) # maximum 9.1

ggplot(df_earthquakes, aes(x = Dataset, y = Magnitude)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + # Rotate x labels for better readability
  labs(title = "Box Plot of Earthquake Magnitudes by Dataset",
       x = "Dataset",
       y = "Magnitude")
```
Histogram 
```{r}
ggplot(df, aes(x = Magnitude, fill = Dataset)) +
  geom_histogram(position = "identity", alpha = 0.6, binwidth = 0.1) +
  scale_fill_brewer(palette = "Set1") +
  labs(title = "Histogram of Earthquake Magnitudes by Dataset",
       x = "Magnitude",
       y = "Frequency") +
  theme(legend.position = "right")
```
Bar Plot of Counts per Earthquake Scale Category
```{r}
ggplot(df_earthquakes, aes(x = Scale)) +
  geom_bar() +
  labs(title = "Bar Plot of Counts per Scale Category",
       x = "Scale",
       y = "Count") +
  geom_text(stat = 'count', 
            aes(label = ..count..), 
            vjust = -0.5)
```

Report on the extent of missing data in the common variables. Is it worth keeping any of the information for variables with missing data? Likewise for common variables with a discrepancy in values. Implement and discuss briefly.
```{r}
na_counts <- colSums(is.na(df_earthquakes)) # Count the number of NA' values's per column
total_rows <- nrow(df_earthquakes) # The total number of rows in the dataset

na_percentage <- round(((na_counts / total_rows) * 100), 2) # Calculate the percentage of NA's per column

na_summary <- data.frame(
  NA_Count = na_counts,
  Percentage_of_NAs = na_percentage
)

na_summary
```

# Initial Exploration 
Before investigating the temporal and spatial aspects of the data, explore and describe the features. 

Things we might be interested in include:

- The distributions of the features. Decide which features to investigate and provide the appropriate plots/measurements.
```{r}

```

- The largest earthquakes, according to magnitude. Choose a number of them and present and discuss in an appropriate way.

```{r}
top10_earthquakes <- df_earthquakes %>%
  arrange(desc(Magnitude)) %>%
  slice_head(n = 10)

# View the top 10 largest earthquakes
print(top10_earthquakes)
```


```{r}
ggplot(earthquakes, aes(x = Longitude, y = Latitude, size = Magnitude)) +
  geom_point(alpha = 0.5) +  # Adjust point transparency with alpha
  theme_minimal() +
  scale_size_continuous(range = c(1, 10)) +  # Adjust the size range for better visualization
  labs(title = "Largest Earthquakes by Magnitude",
       x = "Longitude",
       y = "Latitude",
       size = "Magnitude") +
  theme(legend.position = "right")
```

- The relationship between depth and magnitude, is there any pattern worth noting? Note that the Richter scale is logarithmic, such that an increase of 1 unit corresponds to a tenfold increase in actual magnitude, and a 31-fold increase in energy. How does the picture change when adjusting the magnitude accordingly?
```{r}
# code here
```

- Choose one of the types of events that were removed and briefly investigate these events. When and where did they take place? Provide a map showing this.

```{r}
df_nuclear_explosion <- subset(df, Type == c("Nuclear Explosion", "nuclear explosion"))
# keep rows where type is nuclear explosion
```

```{r}
leaflet(data = df_nuclear_explosion) %>%
  addTiles() %>% 
  addMarkers(data = st_as_sf(df_nuclear_explosion, 
                               coords = c("Longitude", "Latitude"), 
                               crs = 4326)) 
```

```{r}
ggplot() + 
  geom_sf(data = st_as_sf(df_nuclear_explosion, 
                               coords = c("Longitude", "Latitude"), 
                               crs = 4326), 
          colour = "red")
```


```{r}
leaflet(data = top10_earthquakes) %>%
    addMarkers(data = st_as_sf(top10_earthquakes, coords = c("Longitude", "Latitude"), crs = 4326)) 
```


# Temporal Investigation

We will now investigate the frequency and severity of earthquakes over time. For this section you have freedom to choose what to focus on and how to present it, in lieu of step-by-step instructions. 

Some of the questions you might like to answer are:
- How do the frequency of earthquakes in each category compare to estimated frequencies, like those given here or here?
- Do we observe any patterns over time? Is this a definite function of time, or perhaps an artefact of the data?

A time series analysis on the total number of earthquakes over all time 
```{r}
yearly_counts <- df_earthquakes %>%
    mutate(Year = year(DateTime)) %>%
    group_by(Year) %>%
    summarise(sum_counts = n(), 
              mean_magnitude = mean(Magnitude),
              date = mean(DateTime))

head(yearly_counts, n = 3)
```

```{r}
yearly_counts %>% 
  ggplot(aes(x = Year, y = sum_counts)) +
  geom_line() + 
  scale_x_continuous(breaks = seq(min(yearly_counts$Year), 
                                  max(yearly_counts$Year), 
                                  by = 5)) +
  xlab("Time (years)") +
  ylab("Total number of earthquakes") 
```

```{r}
yearly_counts_by_scale <- df_earthquakes %>%
    mutate(Year = year(DateTime)) %>%
    group_by(Year, Scale) %>%
    summarise(sum_counts = n(), 
              mean_magnitude = mean(Magnitude),
              date = mean(DateTime))

head(yearly_counts, n = 3)
```

```{r}
yearly_counts %>% 
  ggplot(aes(x = Year, y = sum_counts)) +
  geom_line() + 
  scale_x_continuous(breaks = seq(min(yearly_counts$Year), 
                                  max(yearly_counts$Year), 
                                  by = 5)) +
  xlab("Time (years)") +
  ylab("Total number of earthquakes") + 
  facet_wrap(~Scale, scales = "free", nrow = 6)
```

# Spatial Exploration
This task is again left mostly open-ended, with the goal being to provide a summary of the spatial distribution of the earthquakes. You may incorporate the temporal nature of the data in any way you see fit. There are various packages you can use for the plotting, although ggplot ’s map data function combined with geom polygon should prove sufficient.

Note that all figures may be static, i.e. no interactivity (since it is a pdf report) and no animation is expected, although you are welcome to include some if you feel you need to!

After providing the global picture, focus on three specific regions, with the corresponding questions merely acting as guidelines/suggestions:

1. The country of T¨urkiye (Turkey). On 6 February 2023, a magnitude 7.8 earthquake
devastated the southern region. How does this compare with previous occurrences in
the region? How often do they experiences major or great earthquakes?
2. Southern Africa, including some area off the South African coast. How many earthquakes
have we experienced since 1965? Which was the largest?
3. An area/country of your choosing. This could be based on your global map, or because
you have an interest in a specific region for whatever reason.

For bonus marks, append your maps with population densities to illustrate whether earthquake “hotspots” tend to threaten large human populations.

End your report with a summary of the key findings. Have fun!
